{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# using the 5 types of flower dataset from kaggle","metadata":{}},{"cell_type":"markdown","source":"importing the necessary packages","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.models as models\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2023-06-13T05:27:20.635796Z","iopub.execute_input":"2023-06-13T05:27:20.636218Z","iopub.status.idle":"2023-06-13T05:27:25.650671Z","shell.execute_reply.started":"2023-06-13T05:27:20.636190Z","shell.execute_reply":"2023-06-13T05:27:25.649507Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Set the device (CPU or GPU)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2023-06-13T05:27:25.653001Z","iopub.execute_input":"2023-06-13T05:27:25.653600Z","iopub.status.idle":"2023-06-13T05:27:25.737416Z","shell.execute_reply.started":"2023-06-13T05:27:25.653565Z","shell.execute_reply":"2023-06-13T05:27:25.735514Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Define the data transforms\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize the image pixels\n])","metadata":{"execution":{"iopub.status.busy":"2023-06-13T05:27:25.739380Z","iopub.execute_input":"2023-06-13T05:27:25.740148Z","iopub.status.idle":"2023-06-13T05:27:25.755570Z","shell.execute_reply.started":"2023-06-13T05:27:25.740105Z","shell.execute_reply":"2023-06-13T05:27:25.754530Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Load the dataset\ndataset = ImageFolder('/kaggle/input/5-flower-types-classification-dataset', transform=transform)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T05:27:25.759139Z","iopub.execute_input":"2023-06-13T05:27:25.760485Z","iopub.status.idle":"2023-06-13T05:27:27.966925Z","shell.execute_reply.started":"2023-06-13T05:27:25.760419Z","shell.execute_reply":"2023-06-13T05:27:27.966029Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Split the dataset into training and testing sets\ntrain_size = int(0.7 * len(dataset))\ntest_size = len(dataset) - train_size\ntrain_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])","metadata":{"execution":{"iopub.status.busy":"2023-06-13T05:27:27.968491Z","iopub.execute_input":"2023-06-13T05:27:27.969060Z","iopub.status.idle":"2023-06-13T05:27:27.996128Z","shell.execute_reply.started":"2023-06-13T05:27:27.969026Z","shell.execute_reply":"2023-06-13T05:27:27.995084Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Create data loaders for batching the data\nbatch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T05:27:27.997667Z","iopub.execute_input":"2023-06-13T05:27:27.998138Z","iopub.status.idle":"2023-06-13T05:27:28.004037Z","shell.execute_reply.started":"2023-06-13T05:27:27.998102Z","shell.execute_reply":"2023-06-13T05:27:28.003092Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Define the neural network architecture\nclass FlowerClassifier(nn.Module):\n    def __init__(self, num_classes):\n        super(FlowerClassifier, self).__init__()\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.fc = nn.Linear(32 * 56 * 56, num_classes)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.conv2(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2023-06-13T05:27:28.005555Z","iopub.execute_input":"2023-06-13T05:27:28.006207Z","iopub.status.idle":"2023-06-13T05:27:28.016341Z","shell.execute_reply.started":"2023-06-13T05:27:28.006174Z","shell.execute_reply":"2023-06-13T05:27:28.015262Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Define the hyperparameters\nnum_classes = len(dataset.classes)\nlearning_rate = 0.001\nnum_epochs = 10","metadata":{"execution":{"iopub.status.busy":"2023-06-13T05:27:28.018156Z","iopub.execute_input":"2023-06-13T05:27:28.018585Z","iopub.status.idle":"2023-06-13T05:27:28.026802Z","shell.execute_reply.started":"2023-06-13T05:27:28.018538Z","shell.execute_reply":"2023-06-13T05:27:28.025870Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Initialize the model, loss function, and optimizer\nmodel = FlowerClassifier(num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T05:27:28.028309Z","iopub.execute_input":"2023-06-13T05:27:28.029059Z","iopub.status.idle":"2023-06-13T05:27:31.216341Z","shell.execute_reply.started":"2023-06-13T05:27:28.029027Z","shell.execute_reply":"2023-06-13T05:27:31.214402Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Training loop\ntotal_step = len(train_loader)\nfor epoch in range(num_epochs):\n    for i, (images, labels) in enumerate(train_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n\n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        # L1 regularization\n        l1_lambda = 0.01\n        l1_norm = sum(p.abs().sum() for p in model.parameters())\n        loss = loss + l1_lambda * l1_norm\n\n        # L2 regularization\n        l2_lambda = 0.01\n        l2_norm = sum(p.pow(2).sum() for p in model.parameters())\n        loss = loss + l2_lambda * l2_norm\n\n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # Print the loss for every 100 batches\n        if (i + 1) % 100 == 0:\n            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{total_step}], Loss: {loss.item():.4f}')","metadata":{"execution":{"iopub.status.busy":"2023-06-13T05:27:31.219740Z","iopub.execute_input":"2023-06-13T05:27:31.220406Z","iopub.status.idle":"2023-06-13T05:32:07.686485Z","shell.execute_reply.started":"2023-06-13T05:27:31.220353Z","shell.execute_reply":"2023-06-13T05:32:07.685459Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Epoch [1/10], Step [100/110], Loss: 0.2728\nEpoch [2/10], Step [100/110], Loss: 0.1501\nEpoch [3/10], Step [100/110], Loss: 0.1391\nEpoch [4/10], Step [100/110], Loss: 0.1463\nEpoch [5/10], Step [100/110], Loss: 0.1489\nEpoch [6/10], Step [100/110], Loss: 0.1349\nEpoch [7/10], Step [100/110], Loss: 0.1483\nEpoch [8/10], Step [100/110], Loss: 0.1425\nEpoch [9/10], Step [100/110], Loss: 0.1386\nEpoch [10/10], Step [100/110], Loss: 0.1379\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluation\nmodel.eval()\nwith torch.no_grad():\n    correct = 0\n    total = 0\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\n    print(f'Test Accuracy: {(correct / total) * 100:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2023-06-13T05:32:07.687667Z","iopub.execute_input":"2023-06-13T05:32:07.688011Z","iopub.status.idle":"2023-06-13T05:32:27.521104Z","shell.execute_reply.started":"2023-06-13T05:32:07.687979Z","shell.execute_reply":"2023-06-13T05:32:27.520029Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Test Accuracy: 100.00%\n","output_type":"stream"}]}]}